\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Overview of remote sensing imagery}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example of how a Landsat scene looks like.}}{2}}
\newlabel{figurelabel}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Convolutional Neural Networks}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Patch-based CNN for remote sensing image classification}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Preprocessing}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces How the bands are structured in the input data.}}{4}}
\newlabel{figurelabel}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}The architecture}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of the proposed convolutional neural network system.}}{4}}
\newlabel{figurelabel}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental results and comparisons}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An example of a Fully Convolutional Network (FCN) for semantic segmentation.}}{5}}
\newlabel{figurelabel}{{4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Loss and accuracy plot for training 9 $\times $ 9 $\times $ 8 patch.}}{6}}
\newlabel{figurelabel}{{5}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Loss and accuracy plot for training 11 $\times $ 11 $\times $ 8 patch.}}{6}}
\newlabel{figurelabel}{{6}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}CONCLUSION}{6}}
\bibcite{c1}{1}
\bibcite{c2}{2}
\bibcite{c3}{3}
\bibcite{c4}{4}
\bibcite{c5}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Illustration of improvement in classification results with number of iterations. Compared to reference map, after certain number of iterations, the accuracy is as follows: (a) 9999 iterations: 72.93\%, (c) 49,999 iterations: 79.12\%, (d) 89,999 iterations: 83.06\%, (e) 129,999 iterations: 84.67\%, (f) 149,999 iterations: 85.60\%.}}{7}}
\newlabel{figurelabel}{{7}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Summary of the accuracy assessment for the classification results produced by the new deep patch-based CNN system (Deep CNN), pixel-based neural network system (Pixel NN), pixel-based CNN (Pixel CNN) and multidimensional patch-based network system (Patch NN).}}{7}}
\newlabel{figurelabel}{{8}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
\bibcite{c6}{6}
\bibcite{c7}{7}
\bibcite{c8}{8}
\bibcite{c9}{9}
\bibcite{c10}{10}
\bibcite{c11}{11}
\bibcite{c12}{12}
\bibcite{c13}{13}
\bibcite{c14}{14}
\bibcite{c15}{15}
\bibcite{c16}{16}
\bibcite{c17}{17}
\bibcite{c18}{18}
\bibcite{c19}{19}
\bibcite{c20}{20}
\bibcite{c21}{21}
\bibcite{c22}{22}
\bibcite{c23}{23}
\bibcite{c24}{24}
\bibcite{c25}{25}
\bibcite{c26}{26}
\bibcite{c27}{27}
\bibcite{c28}{28}
\bibcite{c29}{29}
\bibcite{c30}{30}
\bibcite{c31}{31}
\bibcite{c32}{32}
\bibcite{c33}{33}
\bibcite{c34}{34}
\bibcite{c35}{35}
\bibcite{c36}{36}
\bibcite{c37}{37}
\bibcite{c38}{38}
\bibcite{c39}{39}
\bibcite{c40}{40}
\bibcite{c41}{41}
\bibcite{c42}{42}
\bibcite{c43}{43}
\bibcite{c44}{44}
\bibcite{c45}{45}
\bibcite{c46}{46}
\bibcite{c47}{47}
\bibcite{c48}{48}
\bibcite{c49}{49}
\bibcite{c50}{50}
\bibcite{c51}{51}
\bibcite{c52}{52}
\bibcite{c53}{53}
\bibcite{c54}{54}
\bibcite{c55}{55}
\bibcite{c56}{56}
\bibcite{c57}{57}
